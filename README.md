## Untitled LLM runtime project

A side project I worked on to learn about the inner magic of LLMs. I tried to mostly handwrite it so as to not miss out on the important details.

This is purely educational. And it is currently CPU only, so don't expect much speed. Llama 2 is the only architecture that is supported as of now. 

Might clean this project up the future. Here is an example of the output from tinyllama:

![](/image.png)
